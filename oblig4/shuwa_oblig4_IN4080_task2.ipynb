{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN4080: obligatory assignment 4\n",
    " \n",
    "The final mandatory assignment for IN4080 consists of two parts. The first is about the development of dialogue systems, and the second about machine translation.\n",
    "You are required to get at least 12/20 points to pass. \n",
    "\n",
    "- We assume that you have read and are familiar with IFI’s requirements and guidelines for mandatory assignments, see [here](https://www.uio.no/english/studies/examinations/compulsory-activities/mn-ifi-mandatory.html) and [here](https://www.uio.no/english/studies/examinations/compulsory-activities/mn-ifi-guidelines.html).\n",
    "- This is an individual assignment. You should not deliver joint submissions. \n",
    "- You may redeliver in Devilry before the deadline (__Sunday, November 7 at 23:59__).\n",
    "- Only the last delivery will be read! If you deliver more than one file, put them into a zip-archive. You don't have to include in your delivery the data files already provided for this assignment. \n",
    "- Name your submission _your\\_username\\_in4080\\_mandatory\\_4_\n",
    "\n",
    "Part 1 should be done on your local computer, as it relies on a speech interface that will not work on remote machines. For Part 2, using _Fox_ is preferable, at least for the fine-tuning task.\n",
    "\n",
    "You should deliver a completed version of this Jupyter notebook, containing both your code and explanations about the steps you followed. We want to stress that simply submitting code is __not__ by itself sufficient to complete the assignment - we expect the notebook to also contain explanations of what you have implemented, along with motivations for the choices you made along the way. Preferably use whole sentences, and mathematical formulas if necessary. Explaining in your own words (using concepts we have covered through in the lectures) what you have implemented and reflecting on your solution is an important part of the learning process - take it seriously!\n",
    "\n",
    "Regarding the use of LLMs (ChatGPT or similar): you are allowed to use them as 'sparring partner', for instance to clarify something you have not understood. However, you are __not__ allowed to use them to generate solutions (either in part or in full) to the assignment tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Dialogue systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective in this part is to build a spoken conversational interface for a (simulated) elevator. \n",
    "\n",
    "### Basic setup\n",
    "\n",
    "First, let's make sure that we have `ipywidgets` installed::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the simulated elevator is provided below. The elevator is displayed using simple widgets (where the current floor is shown in green). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import asyncio\n",
    "\n",
    "import time, random, string, threading\n",
    "from typing import List, Tuple, Dict, Set\n",
    "   \n",
    "class BasicElevator:\n",
    "    \"\"\"Representation of an elevator. The elevator is simulated using a GUI\"\"\"\n",
    "    \n",
    "    def __init__(self, start_floor:int =1, nb_floors=10):\n",
    "        \"\"\"Initialised a new elevator, placed on the first floor\"\"\"\n",
    "        \n",
    "        # Current floor of the elevator\n",
    "        self.cur_floor: int = start_floor\n",
    "        self._moving: bool = False\n",
    "        \n",
    "        self._build_gui(nb_floors)\n",
    "\n",
    "        # (Possibly empty) list of next floor stops to reach\n",
    "        self.nextstops: List[int] = []\n",
    "\n",
    "        display(self.gui)\n",
    "\n",
    "\n",
    "    def move_to_floor(self, floor_number: int):\n",
    "        \"\"\"Move to a given floor (by adding it to a stack of floors to reach)\"\"\"\n",
    "        \n",
    "        if floor_number < 1 or floor_number > len(self.floors):\n",
    "            raise RuntimeError(\"Floor number must be between 1 and %i\"%len(self.floors))\n",
    "\n",
    "        self.nextstops.append(floor_number)\n",
    "        asyncio.create_task(self._trigger_movement())\n",
    "        \n",
    "        \n",
    "    def stop(self):\n",
    "        \"\"\"Stops all movements of the elevator\"\"\"\n",
    "        \n",
    "        self.nextstops.clear()\n",
    "        asyncio.create_task(self._trigger_movement())\n",
    "\n",
    "\n",
    "    def _build_gui(self, nb_floors):\n",
    "        \"\"\"Creates the GUI for the elevator, with a status label and a visual representation\n",
    "        of the floors, where the current floor is indicated in green.\"\"\"\n",
    "\n",
    "        # Displaying the current status of the elevator (still or going up or down)\n",
    "        status_label = widgets.HTML(\"<b>Status</b>: \")\n",
    "        self.status = widgets.Label(\"Still\")\n",
    "        status_box = widgets.HBox([status_label, self.status])\n",
    "\n",
    "        # Displaying the floors on a vertical axis\n",
    "        self.floors = []\n",
    "        floor_layout = widgets.Layout(width='50px', height='30px', border='2px solid black',justify_content=\"center\")\n",
    "        for i in range(1, nb_floors+1):\n",
    "            floor = widgets.Label(value=str(i), layout=floor_layout)\n",
    "            floor.style = {\"background\":(\"white\" if i!=self.cur_floor else \"lightgreen\")}\n",
    "            self.floors.append(floor)\n",
    "\n",
    "        # Create a vertical box container to hold the boxes\n",
    "        vbox = widgets.VBox([status_box] + self.floors[::-1])\n",
    "        self.gui = vbox\n",
    "\n",
    "    async def _trigger_movement(self, speed=1.0):\n",
    "        \"\"\"Triggers the movement of the elevator towards the next stops in the list.\n",
    "        The elevator moves one floor at a time, waiting 'speed' seconds between floors.\"\"\"\n",
    "\n",
    "        # If already moving, do nothing\n",
    "        if self._moving:\n",
    "            return\n",
    "        \n",
    "        self._moving = True\n",
    "        while self.nextstops:\n",
    "            floor_to_reach = self.nextstops[0]\n",
    "            \n",
    "            if self.cur_floor == floor_to_reach:\n",
    "                self.nextstops.pop(0)\n",
    "                continue\n",
    "            \n",
    "            if floor_to_reach > self.cur_floor:\n",
    "                next_floor = self.cur_floor + 1\n",
    "                self.status.value = \"UP\"\n",
    "            else:\n",
    "                next_floor = self.cur_floor - 1\n",
    "                self.status.value = \"DOWN\"\n",
    "            \n",
    "            # Added sleep to simulate time taken to move between floors\n",
    "            await asyncio.sleep(speed)\n",
    "\n",
    "            # Update UI safely\n",
    "            self.floors[self.cur_floor - 1].style.background = \"white\"\n",
    "            self.floors[next_floor - 1].style.background = \"lightgreen\"\n",
    "            self.cur_floor = next_floor\n",
    "             \n",
    "        self.status.value = \"Still\"\n",
    "        self._moving = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elevator can be easily controlled through the functions `move_to_floor` and `stop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc428e5ca3254373910c6dd4e6decb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Status</b>: '), Label(value='Still'))), Label(value='10', layout=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elevator = BasicElevator()\n",
    "elevator.move_to_floor(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make our elevator controllable through a speech interface instead of using function calls.\n",
    "\n",
    "Before we begin, you need to install `pyaudio` (for audio processing), `whisper` (for speech recognition), and `pyttsx3` (for speech synthesis):\n",
    "```bash\n",
    "%pip install pyaudio openai-whisper pyttsx3\n",
    "```\n",
    "\n",
    "Audio processing in Python can be quite tricky, as it works differently from OS to OS. In particular, if you are running on Linux and the TTS is not working, install the following packages on your machine: `sudo apt update && sudo apt install espeak ffmpeg libespeak1`. If you are on MacOS and TTS is not working, try installing portaudio using Homebrew: `brew install portaudio`.\n",
    "\n",
    "If you run into issues with `pyaudio`, try using `sounddevice` instead: ```bash pip install sounddevice```.\n",
    "\n",
    "_If you still run into issues with the audio processing, please let us know (ideally on Discourse), we have a number of fixes that can help_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech interface\n",
    "\n",
    "The `TalkingElevator` class below extends the basic simulated elevator with speech input and output. \n",
    "\n",
    "Upon clicking on the recording button, speech is recorded from the user's microphone, and continues until the stop button is clicked. The speech recognition engine `Whisper` from OpenAI is then employed to transcribe the spoken input (either on GPU, if you have a GPU on your machine, or on CPU). The transcription result is then sent to the `process_input` function, which is responsible for determining the system response. \n",
    "\n",
    "We are going to focus on implementing this `process_input` method. Note this system reaction to new user inputs may comprise both verbal responses (to be uttered by the system through the `_say_to_user` method) and physical actions (through the `move_to_floor` and `stop` methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, time\n",
    "import numpy as np\n",
    "from typing import List, Literal, Tuple, Dict, Set\n",
    "import whisper, pyttsx3\n",
    "import warnings\n",
    "\n",
    "class TalkingElevator(BasicElevator):\n",
    "    \"\"\"Extension of the simulated elevator with a speech interface\"\"\"\n",
    "    \n",
    "    def __init__(self, audio_backend:Literal[\"pyaudio\",\"sounddevice\"]=\"pyaudio\"):\n",
    "        \"\"\"Initialises the Talking Elevator, loading the ASR model and setting up the GUI.\n",
    "        The audio_backend parameter specifies which library to use for audio recording\n",
    "        (either 'pyaudio' or 'sounddevice').\"\"\"\n",
    "\n",
    "        self.audio_backend = audio_backend\n",
    "        print(\"Loading ASR model\", end=\"...\", flush=True)\n",
    "        self.asr_engine = whisper.load_model(\"small.en\")\n",
    "        print(\"Done\")\n",
    "        \n",
    "        # Initializing the GUI\n",
    "        BasicElevator.__init__(self)\n",
    "\n",
    "        # Starts the dialogue\n",
    "        self.dialogue_history = []\n",
    "        self._say_to_user(\"Hi, what can I do for you today?\")\n",
    "    \n",
    "\n",
    "    def process_input(self, user_input: str, conf_score:float=1.0):\n",
    "        \"\"\"Processes the (transcribed) user input, and respond appropriately \n",
    "        (through a verbal response and possibly also an action, such as moving floors)\"\"\"\n",
    "\n",
    "        self._add_to_dialogue_history(user_input, speaker=\"user\", conf_score=conf_score)\n",
    "\n",
    "        # Dummy response. Should be replaced by the actual dialogue behaviour\n",
    "        self._say_to_user(\"Sorry, I don't understand you, pal\")\n",
    "\n",
    "    \n",
    "    def _say_to_user(self, system_response: str):\n",
    "        \"\"\"Say something back to the user, and add the dialogue turn to the history. The \n",
    "        synthesis is done using the pyttsx3 library.\"\"\"\n",
    "\n",
    "        self._add_to_dialogue_history(system_response, speaker=\"elevator\")\n",
    "        \n",
    "        # Due to resource management issues, we initialize a new TTS engine for each utterance\n",
    "        tts_engine = pyttsx3.init()  \n",
    "        tts_engine.say(system_response)\n",
    "        tts_engine.runAndWait()\n",
    "        tts_engine.stop()\n",
    "        del tts_engine\n",
    "\n",
    "\n",
    "    def _add_to_dialogue_history(self, turn:str , speaker:str, conf_score:float=1.0):\n",
    "        \"\"\"Adds a new (user or system) turn to the dialogue history list, and displays it\n",
    "         on the chat window displaying the turns\"\"\"\n",
    "\n",
    "        self.dialogue_history.append({\"speaker\":speaker, \"text\":turn, \n",
    "                                      \"conf_score\":conf_score, \"timesamp\":time.time()})\n",
    "        \n",
    "        self.history_area.value += \"&nbsp;<strong>%s</strong>:  %s\"%(speaker.title(), turn)\n",
    "        if conf_score < 1.0:\n",
    "            self.history_area.value += \" (%.2f)\"%(conf_score)\n",
    "        self.history_area.value += \"<br>\"\n",
    "   \n",
    "    \n",
    "    def _build_gui(self, nb_floors):\n",
    "        \"\"\"GUI for the Talking elevator, comprising (beyond the simulated elevator from \n",
    "        BasicElevator) a chat window showing the dialogue turns, and buttons to record\n",
    "        the user input. \n",
    "        The user should first click on the record button, then on stop when they have finished.\n",
    "        Once the stop button is clicked, the audio is transcribed by Whisper, and finally \n",
    "        forwarded to the process_input function.\"\"\"\n",
    "\n",
    "        BasicElevator._build_gui(self, nb_floors)\n",
    "\n",
    "        self.frames = []\n",
    "        self.recording = False\n",
    "\n",
    "        def record(chunk_size=1024):\n",
    "            \"\"\"Record audio chunks to a buffer.\"\"\"\n",
    "            self.recording = True\n",
    "\n",
    "            frames = []\n",
    "            if self.audio_backend==\"pyaudio\":\n",
    "                import pyaudio\n",
    "                p = pyaudio.PyAudio()\n",
    "                stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, \n",
    "                                frames_per_buffer=chunk_size)\n",
    "                while self.recording:\n",
    "                    self.frames.append(stream.read(chunk_size))\n",
    "                stream.close()\n",
    "                p.terminate()\n",
    "\n",
    "            elif self.audio_backend==\"sounddevice\":\n",
    "                import sounddevice\n",
    "                stream = sounddevice.InputStream(samplerate=16000, channels=1, blocksize=chunk_size)\n",
    "                stream.start()\n",
    "                while self.recording:\n",
    "                    data, overflowed = stream.read(chunk_size)\n",
    "                    if overflowed:\n",
    "                        print(\"Overflow occurred!\")\n",
    "                    self.frames.append(data.copy())\n",
    "                stream.stop()\n",
    "                stream.close()\n",
    "\n",
    "        def on_record_button_clicked(b):\n",
    "            \"Starts the recording\"\n",
    "            record_button.disabled=True\n",
    "            stop_button.disabled=False\n",
    "            audio_status.value = \"Recording...\"\n",
    "            self.frames = []  # Clear previous recordings\n",
    "            thread = threading.Thread(target=record)\n",
    "            thread.start()\n",
    "\n",
    "        def on_stop_button_clicked(b):\n",
    "            \"stops the recording, runs Whisper, and forward the result to process_input\"\n",
    "            self.recording = False\n",
    "            record_button.disabled=False\n",
    "            stop_button.disabled=True\n",
    "            audio_status.value = \"Transcribing...\"\n",
    "            if self.audio_backend==\"pyaudio\":\n",
    "              audio_data = np.frombuffer(b\"\".join(self.frames), np.int16).astype(np.float32) * (1 / 32768.0)\n",
    "            elif self.audio_backend==\"sounddevice\":\n",
    "                audio_data = np.concatenate(self.frames, axis=0).flatten()\n",
    "            output = self.asr_engine.transcribe(audio_data, fp16=False)\n",
    "            audio_status.value = \"Done transcribing.\"\n",
    "\n",
    "            # We define the confidence score based on the log-probabilities\n",
    "            conf_score = np.exp(np.mean([segment[\"avg_logprob\"] for segment in output[\"segments\"]]))\n",
    "            # (and we push those up a bit, as the Whisper scores seem too low)\n",
    "            conf_score = min(1, conf_score*1.2)\n",
    "\n",
    "            # Finally, we process the input\n",
    "            self.process_input(output[\"text\"], conf_score)\n",
    "\n",
    "        # The record and stop buttons\n",
    "        record_button = widgets.Button(icon=\"microphone\")\n",
    "        stop_button = widgets.Button(icon=\"stop\", disabled=True)\n",
    "        audio_status = widgets.Label(\"\")\n",
    "        record_button.on_click(on_record_button_clicked)\n",
    "        stop_button.on_click(on_stop_button_clicked)\n",
    "        \n",
    "        # The chat area\n",
    "        self.history_area = widgets.HTML(layout=widgets.Layout(width=\"600px\", height=\"300px\", \n",
    "                                                               border='1px solid black', overflow='scroll'))\n",
    "\n",
    "        # The right side of the GUI\n",
    "        right_side = widgets.VBox([widgets.Label(\"\"), self.history_area, widgets.HBox([record_button, stop_button, audio_status])])\n",
    "        self.gui = widgets.HBox([self.gui, right_side])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ASR model...Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f44fc30fd8241c78bb35b6f8258c6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(HTML(value='<b>Status</b>: '), Label(value='Still'))), Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elevator = TalkingElevator(audio_backend=\"pyaudio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Note**: The current implementation reloads the TTS and ASR models every time, which means that you may run into a \"CUDA: out of memory\" error if you reinitialise the `TalkingElevator` many times. If this happens, simply restart the Python kernel, which will clear the memory on both the CPU and the GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Intent recognition\n",
    "\n",
    "We wish our talking elevator to support the following functionalities:\n",
    " \n",
    "- If the user express a wish to go to floor $X$ (where $X$ is an integer value between 1 and 10), the elevator should go to that floor. The interface should allow for several ways to express a given intent, such as \"_Please go to the $X$-th floor_\" or \"_Floor $X$, please_\".\n",
    "- The user requests can also be relative, for instance \"_Go one floor up_\".\n",
    "- The elevator should provide _grounding_ feedback to the user. For instance, it should respond \"_Ok, going to the $X$-th floor_\" after a user request to move to $X$.  \n",
    "- The elevator should handle misunderstandings and uncertainties, e.g. by requesting the user to repeat, or asking the user to confirm if the intent is uncertain (say, when its confidence score is lower than 0.5). \n",
    "- The elevator should also allow the user to ask where the office of a given employee is located. For instance, the user could ask \"_where is Erik Velldal's office?_\", and the elevator would provide a response such as \"_The office of Erik Velldal is on the 4th floor. Do you wish to go there?_\".  We provide you with the office numbers of a small set of IFI employees in the `OFFICES` dictionary (see below).\n",
    "- The elevator should also be able to inform the user about the current floor (such as replying to \"_Which floor are we on?_\" or \"_Are we on the 5th floor?_\"). \n",
    "- Finally, if the user asks the elevator to stop (or if the user says \"_no_\" after a grounding feedback \"_Ok, going to floor $X$._\"), the elevator should stop, and ask for clarification regarding the actual user intent. \n",
    "\n",
    "To implement this conversational behaviour, we will rely on a classical NLU-based approach in which we will recognise the user _intent_, and then determine a response based on the recognised intent(s). \n",
    "\n",
    "__Task 1.1__ (1 point): You first need to define a list of user intents that cover the kinds of user inputs you expect to observe in this talking elevator, such as `RequestMoveToFloor` or `Confirm`. This is a design question, and there is no obvious right or wrong answer. Define below the intents you want to cover, along with an explanation and a few examples of user inputs for each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Provide here the list of intent classes you have defined, together with an explanation and a few examples -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.2__ (1 points): We wish to build a classifier any user input to a probability distribution over those intents, and start by creating a small, synthetic training set. Make a list of about 100 user utterances, each labelled with an intent defined above. You can \"make up\" those utterances yourself, or ask someone else to come with alternative formulations if you lack inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_utterances =  [(\"I really like the IN4080 course\", \"OutOfCoverage\"), #... \n",
    "                        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train an intent classifier based on the labelled utterances you have defined. You can choose between the following approaches:\n",
    "- you can use the [SetFit](https://github.com/huggingface/setfit) library to fine-tune a sentence-transformer model for classify your utterances. If you choose this option, install the `setfit` library  (`pip install setfit`) and read the [Setfit quickstart guide](https://huggingface.co/docs/setfit/quickstart) to find out how to use it.\n",
    "- Alternatively (if SetFit is too slow on your machine or you have technical problems with it), you can also train a simple classifier based on sentence embeddings from `sentence-transformers` (install it using `pip install sentence-transformers`). You can e.g. use a k-NN classifier or a logistic regression model from `sklearn` on top of the sentence embeddings. Or even use bag-of-words features if you prefer.\n",
    "\n",
    "__Task 1.3__ (2 points): Train your intent classifier based on `labelled_utterances`. Once you are done, fill the implementation of the `IntentClassifier` class below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassifier:\n",
    "\n",
    "    def __init__(self, init_args):\n",
    "        \"\"\"Initialises the intent classifier, for instance by loading a fine-tuned \n",
    "        SetFit model. You should replace init_args by whatever arguments you need.\"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"Must be implemented\")\n",
    "\n",
    "\n",
    "    def get_intent_distrib(self, utterance:str) -> Dict[str, float]:\n",
    "        \"\"\"Applies the trained model on a new utterance. The method should return a\n",
    "        dictionary that maps each possible intent category to a probability.\"\"\"\n",
    "\n",
    "        raise NotImplementedError(\"Must be implemented\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then test your classifier as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = IntentClassifier()\n",
    "classifier.get_intent_distrib(\"Take me to the fifth floor, please\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have any test data, we cannot really conduct an evaluation of the classification performance, but this step would be of course strongly advised when developing a real system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slot filling\n",
    "\n",
    "In addition to the intents themselves, we also wish to detect some slots, such as floor numbers or person names. For this step, we will not use a data-driven model, but rather rely on an old-fashioned, rule-based approach:\n",
    "- For floor numbers, we will rely on string matching (with regular expressions or basic string search) that detect patterns such as \"X floor\" (where X is [first,second, third, fourth, fifth, sixth, seventh, eighth, ninth, tenth]) or \"floor X\" (where X is between 1 and 10).\n",
    "- For person names, we have a predefined list of person names to detect (employees at IFI), and we should simply search for their occurrence in the user input. The simplest implementation is to just for look for exact occurrences. However, since speech recognition will often struggle to recognize foreign person names, an even better approach would be to search for names that are phonetically close (you can use the `jellyfish` library for this).\n",
    "\n",
    "The results of the slot filling should be a dictionary mapping slot names to a canonical form of the slot value. For instance, if the utterance contains the expression \"ninth floor\", the resulting slot dictionary should be `{\"floor_number\":9}`. Similarly, the `employee_name` slot should be a name present in `OFFICES` dictionary. \n",
    "\n",
    "__Task 1.4__ (2 points): Implement the method `fill_slots` that will detect the occurrence of those slots in the user input.<br>\n",
    "(+ 1 bonus point if you implement a fuzzy matching strategy to find person names that are phonetically close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Floor numbers for a subset of the IFI employees\n",
    "OFFICES = {'Adín Ramírez Rivera': 4, 'Andreas Austeng': 4, 'Anne H Schistad Solberg': 4, \n",
    "           'Arild Torolv Søetorp Waaler': 9, 'Audun Jøsang': 9, 'Birthe Soppe': 4, 'Carsten Griwodz': 4,\n",
    "           'Dag Sjøberg': 9, 'Dag Trygve Eckhoff Wisland': 5, 'Einar Broch Johnsen': 8, \n",
    "           'Eric Bartley Jul': 10, 'Erik Velldal': 4, 'Henrik Skaug Sætra': 7, 'Ingrid Chieh Yu': 8,\n",
    "           'Jørn Anders Braa': 6, 'Kristin Bråthen': 4, 'Kyrre Glette': 4, 'Lars Groth': 6, \n",
    "           'Lilja Øvrelid': 4, 'Maja Van Der Velden': 7, 'Martin Giese': 9, 'Michael Welzl': 5, \n",
    "           'Miria Grisot': 6, 'Nils Gruschka': 9, 'Olaf Owe': 9, 'Ole Christian Lingjærde': 4, \n",
    "           'Ole Hanseth': 6, 'Paulo Ferreira': 10, 'Philipp Dominik Häfliger': 5, 'Philipp Häfliger': 5, \n",
    "           'Roman Vitenberg': 4, 'Silvia Lizeth Tapia Tarifa': 8, 'Stephan Oepen': 4, \n",
    "           'Sundeep Sahay': 6, 'Thomas Peter Plagemann': 4, 'Tone Bratteteig': 7, 'Torbjørn Rognes': 8, \n",
    "           'Truls Erikson': 6, 'Viktoria Stray': 10, 'Yngvar Berg': 5, 'Yves Scherrer': 4, \n",
    "           'Özgü Mira Alay-Erduran': 4}\n",
    "\n",
    "def fill_slots(user_input:str) -> Dict[str,str]:\n",
    "    \"\"\"Extracts the set of slots detected in the user inputs. More precisely, the method\n",
    "    should detect both floor numbers and person names, and return a dictionary mapping slot \n",
    "    names (in this case either `floor_number` or `employee_name`) to its corresponding\n",
    "    value, in canonical form (integer for the floor number, string for the employee name)\"\"\"\n",
    "\n",
    "    raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response selection\n",
    "\n",
    "The next step is to implement the response selection mechanism. The response will depend on various factors:\n",
    "- the inferred user intents from the user utterance\n",
    "- the detected slot values in the user utterance (if any)\n",
    "- the current floor\n",
    "- the list of next floor stops that are yet to be reached\n",
    "- the dialogue history (as a list of dialogue turns).\n",
    "\n",
    "The response may consist of verbal responses (enacted by calls to `_say_to_user`) but also physical actions, represented by calls to either `move_to_floor` or `stop`. \n",
    "\n",
    "__Task 1.5__ (3 points): Implement the method `_respond`, which is responsible for selecting and executing those responses. The responses should satisfy the aforementioned conversational criteria (provide grounding feedback, use confirmations and clarification requests etc.). This method will consist in practice of many _if...then...else_ blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _respond(self, intent_distrib: Dict[str, float], slots: Dict[str,str]) :\n",
    "    \"\"\"Given a probability distribution over possible intents, an a (possibly empty) list\n",
    "    of detected slots in the user input, decide how to react. The method should lead\n",
    "    to calls to both physical actions (move_to_floor, stop) and dialogue responses \n",
    "    (via _say_to_user).\"\"\"\n",
    "\n",
    "    raise NotImplementedError(\"\")\n",
    "\n",
    "setattr(TalkingElevator, \"_respond\", _respond)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "The last step is to implement the `process_input` method in the `TalkingElevator` class. The method should rely on the intent recognition, slot filling and response selection mechanism (which you have implemented in the previous steps) to react to a given user input.\n",
    "\n",
    "**Task 1.6** (1 point): Implement the `process_input` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_input(self, user_input: str, conf_score:float=1.0):\n",
    "    \"\"\"Processes the (transcribed) user input, and respond appropriately \n",
    "    (through a verbal response and possibly also an action, such as moving floors).\n",
    "    The method should rely on the intent classifier, slot-filling function, and\n",
    "    response selection function.\"\"\"\n",
    "\n",
    "    self._add_to_dialogue_history(user_input, speaker=\"user\", conf_score=conf_score)\n",
    "    raise NotImplementedError()\n",
    "\n",
    "setattr(TalkingElevator, \"process_input\", process_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to test our talking elevator: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevator = TalkingElevator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your talking elevator will mostly likely not function properly right from the start. Identify what works and what doesn't and correct the code you have developed in Tasks 1.1 - 1.6 until your system meets the specifications we have outlined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Machine translation\n",
    "\n",
    "In this part, we evaluate a pre-trained machine translation model on data from the Lord of the Rings movies and fine-tune it to improve the translation quality.\n",
    "\n",
    "### Data\n",
    "\n",
    "We provide you with two files, `lotr.detok.de` and `lotr.detok.en`, containing German and English movie subtitles. These two files constitute a so-called _parallel corpus_, i.e. each sentence/line in German corresponds to a sentence/line in English. The two files have the same number of lines and the German sentence on line $i$ corresponds to the English sentence on line $i$. The subtitles are extracted from the [OpenSubtitles-2018](https://opus.nlpl.eu/OpenSubtitles/corpus/version/OpenSubtitles) corpus.\n",
    "\n",
    "Here are the first ten lines of the two files:\n",
    "\n",
    "<style scoped>\n",
    "table {\n",
    "  font-size: 12px;\n",
    "}\n",
    "</style>\n",
    "| Nb  | German (`lotr.detok.de`)         | English (`lotr.detok.en`)      |\n",
    "|---|----------------------------------|--------------------------------|\n",
    "| 1 | Die Welt ist im Wandel. | The world is changed.   |\n",
    "| 2 | Ich spüre es im Wasser. | I feel it in the water. |\n",
    "| 3 | Ich spüre es in der Erde. | I feel it in the earth. |\n",
    "| 4 | Ich rieche es in der Luft. | I smell it in the air. |\n",
    "| 5 | Vieles, was einst war, ist verloren, da niemand mehr lebt, der sich erinnert. | Much that once was is lost. For none now live who remember it. |\n",
    "| 6 | Es begann mit dem Schmieden der Großen Ringe. | It began with the forging of the Great Rings. |\n",
    "| 7 | 3 wurden den Elben gegeben, den unsterblichen, weisesten und reinsten aller Wesen. | Three were given to the Elves: Immortal, wisest and fairest of all beings. |\n",
    "| 8 | 7 den Zwergenherrschern, großen Bergleuten und Handwerkern in ihren Hallen aus Stein. | Seven to the Dwarf-lords: Great miners and craftsmen of the mountain halls. |\n",
    "| 9 | Und 9... 9 Ringe wurden den Menschen geschenkt, die vor allem anderen nach Macht streben. | And nine nine rings were gifted to the race of Men who, above all else, desire power. |\n",
    "| 10 | Denn diese Ringe bargen die Kraft und den Willen, jedes Volk zu leiten. | For within these rings was bound the strength and will to govern each race. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: unbabel-comet==2.2.2 in /fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: entmax<2.0,>=1.1 in /fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (1.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /fp/projects01/ec30/software/easybuild/software/nlpl-huggingface-hub/0.27.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (0.27.1)\n",
      "Requirement already satisfied: jsonargparse==3.13.1 in /fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.20.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-numpy/1.24.4-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.4.1 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (1.5.3)\n",
      "Collecting protobuf<5.0.0,>=4.24.4 (from unbabel-comet==2.2.2)\n",
      "  Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pytorch-lightning<3.0.0,>=2.0.0 in /fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (2.5.5)\n",
      "Requirement already satisfied: sacrebleu<3.0.0,>=2.0.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/04-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (2.5.1)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (1.10.1)\n",
      "Requirement already satisfied: sentencepiece<0.2.0,>=0.1.96 in /fp/projects01/ec30/software/easybuild/software/nlpl-sentencepiece/0.1.99-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.6.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-pytorch/2.1.2-foss-2022b-cuda-12.0.0-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (2.1.2)\n",
      "Requirement already satisfied: torchmetrics<0.11.0,>=0.10.2 in /fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (0.10.3)\n",
      "Requirement already satisfied: transformers<5.0,>=4.17 in /fp/projects01/ec30/software/easybuild/software/nlpl-transformers/4.47.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet==2.2.2) (4.47.1)\n",
      "Requirement already satisfied: PyYAML>=3.13 in /cluster/software/EL9/easybuild/software/PyYAML/6.0-GCCcore-12.2.0/lib/python3.10/site-packages (from jsonargparse==3.13.1->unbabel-comet==2.2.2) (6.0)\n",
      "Requirement already satisfied: filelock in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (3.8.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-huggingface-hub/0.27.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (2023.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (21.3)\n",
      "Requirement already satisfied: requests in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (4.66.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (4.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from pandas>=1.4.1->unbabel-comet==2.2.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from pandas>=1.4.1->unbabel-comet==2.2.2) (2022.6)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (0.15.2)\n",
      "Requirement already satisfied: portalocker in /fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/04-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (2.8.2)\n",
      "Requirement already satisfied: regex in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (2023.10.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (0.9.0)\n",
      "Requirement already satisfied: colorama in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (0.4.6)\n",
      "Requirement already satisfied: lxml in /cluster/software/EL9/easybuild/software/lxml/4.9.2-GCCcore-12.2.0/lib/python3.10/site-packages (from sacrebleu<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (4.9.2)\n",
      "Requirement already satisfied: sympy in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch>=1.6.0->unbabel-comet==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch>=1.6.0->unbabel-comet==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch>=1.6.0->unbabel-comet==2.2.2) (3.1.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /fp/projects01/ec30/software/easybuild/software/nlpl-tokenizers/0.21.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers<5.0,>=4.17->unbabel-comet==2.2.2) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /fp/projects01/ec30/software/easybuild/software/nlpl-transformers/4.47.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers<5.0,>=4.17->unbabel-comet==2.2.2) (0.4.5)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (3.9.1)\n",
      "Requirement already satisfied: setuptools in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (63.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (3.0.9)\n",
      "Requirement already satisfied: six>=1.5 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.4.1->unbabel-comet==2.2.2) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->unbabel-comet==2.2.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.19.3->unbabel-comet==2.2.2) (2022.9.24)\n",
      "Requirement already satisfied: mpmath>=0.19 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from sympy->torch>=1.6.0->unbabel-comet==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cluster/software/EL9/easybuild/software/JupyterLab/4.0.3-GCCcore-12.2.0/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet==2.2.2) (4.0.3)\n",
      "Using cached protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Installing collected packages: protobuf\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-4.25.8\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install unbabel-comet==2.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "We will a pretrained machine translation model for German-to-English translation. The model is available on the HuggingFace model hub and can be used with the `transformers` library.\n",
    "\n",
    "Let us first make sure that all required modules are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /fp/projects01/ec30/software/easybuild/software/nlpl-pytorch/2.1.2-foss-2022b-cuda-12.0.0-Python-3.10.8/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: transformers in /fp/projects01/ec30/software/easybuild/software/nlpl-transformers/4.47.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (4.47.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: evaluate in /fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/04-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: sacrebleu in /fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/04-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: sacremoses in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (0.1.1)\n",
      "Requirement already satisfied: sentencepiece in /fp/projects01/ec30/software/easybuild/software/nlpl-sentencepiece/0.1.99-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (0.1.99)\n",
      "Collecting unbabel-comet\n",
      "  Downloading unbabel_comet-2.2.7-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from torch) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /fp/projects01/ec30/software/easybuild/software/nlpl-huggingface-hub/0.27.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from torch) (2023.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-huggingface-hub/0.27.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /fp/projects01/ec30/software/easybuild/software/nlpl-numpy/1.24.4-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /cluster/software/EL9/easybuild/software/PyYAML/6.0-GCCcore-12.2.0/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /fp/projects01/ec30/software/easybuild/software/nlpl-tokenizers/0.21.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /fp/projects01/ec30/software/easybuild/software/nlpl-transformers/4.47.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from transformers) (4.66.3)\n",
      "Requirement already satisfied: psutil in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from accelerate) (5.9.4)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: dill in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: pandas in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from evaluate) (1.5.3)\n",
      "Requirement already satisfied: xxhash in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: portalocker in /fp/projects01/ec30/software/easybuild/software/nlpl-nlptools/04-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from sacrebleu) (2.8.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /cluster/software/EL9/easybuild/software/lxml/4.9.2-GCCcore-12.2.0/lib/python3.10/site-packages (from sacrebleu) (4.9.2)\n",
      "Requirement already satisfied: click in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from sacremoses) (8.1.7)\n",
      "Requirement already satisfied: joblib in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from sacremoses) (1.2.0)\n",
      "Collecting entmax<2.0,>=1.1 (from unbabel-comet)\n",
      "  Downloading entmax-1.3-py3-none-any.whl.metadata (348 bytes)\n",
      "Collecting jsonargparse==3.13.1 (from unbabel-comet)\n",
      "  Downloading jsonargparse-3.13.1-py3-none-any.whl.metadata (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<5.0.0,>=4.24.4 (from unbabel-comet)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting pytorch-lightning<3.0.0,>=2.0.0 (from unbabel-comet)\n",
      "  Downloading pytorch_lightning-2.5.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.5.4 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from unbabel-comet) (1.10.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting torchmetrics<0.11.0,>=0.10.2 (from unbabel-comet)\n",
      "  Downloading torchmetrics-0.10.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
      "Requirement already satisfied: aiohttp in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from pandas->evaluate) (2022.6)\n",
      "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet)\n",
      "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /fp/projects01/ec30/software/easybuild/software/nlpl-scipy-ecosystem/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /cluster/software/EL9/easybuild/software/JupyterLab/4.0.3-GCCcore-12.2.0/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-python-candy/01-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /fp/projects01/ec30/software/easybuild/software/nlpl-datasets/3.2.0-foss-2022b-Python-3.10.8/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: setuptools in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning<3.0.0,>=2.0.0->unbabel-comet) (63.4.3)\n",
      "Requirement already satisfied: six>=1.5 in /cluster/software/EL9/easybuild/software/Python/3.10.8-GCCcore-12.2.0/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading unbabel_comet-2.2.7-py3-none-any.whl (90 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.0/91.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonargparse-3.13.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sentencepiece-0.2.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading entmax-1.3-py3-none-any.whl (13 kB)\n",
      "Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytorch_lightning-2.5.5-py3-none-any.whl (832 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-0.10.3-py3-none-any.whl (529 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m529.7/529.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sentencepiece, protobuf, jsonargparse, lightning-utilities, torchmetrics, entmax, accelerate, pytorch-lightning, unbabel-comet\n",
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config, accelerate-estimate-memory, accelerate-launch and accelerate-merge-weights are installed in '/fp/homes01/u01/ec-shuwa/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts comet-compare, comet-mbr, comet-score and comet-train are installed in '/fp/homes01/u01/ec-shuwa/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-1.11.0 entmax-1.3 jsonargparse-3.13.1 lightning-utilities-0.15.2 protobuf-4.25.8 pytorch-lightning-2.5.5 sentencepiece-0.2.1 torchmetrics-0.10.3 unbabel-comet-2.2.7\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers accelerate evaluate sacrebleu sacremoses sentencepiece unbabel-comet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bilingual model is called [`opus-mt-de-en`](https://huggingface.co/Helsinki-NLP/opus-mt-de-en) and has been trained by the Helsinki-NLP group. Like (almost) all HuggingFace models, it consists of a _tokenizer_ and the _sequence-to-sequence model_ properly speaking. We need to load both separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fp/projects01/ec30/software/easybuild/software/nlpl-pytorch/2.1.2-foss-2022b-cuda-12.0.0-Python-3.10.8/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"helsinki-nlp/opus-mt-de-en\")\n",
    "translator = transformers.AutoModelForSeq2SeqLM.from_pretrained(\"helsinki-nlp/opus-mt-de-en\")\n",
    "\n",
    "# Change \"cuda\" to \"cpu\" if you're running on a machine without GPU\n",
    "device = \"cuda\"\n",
    "translator = translator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transformers` library will automatically download the models from the HuggingFace hub the first time you run this cell, so it may take a bit longer.\n",
    "\n",
    "Let's take the first two German sentences, tokenize them, and translate them to English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   55,   401,    29,    49,  9012,     3,     0, 58100, 58100],\n",
      "        [  105,  2768,  1691,    18,    65,    49,   672,     3,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer([\"Die Welt ist im Wandel.\", \"Ich spüre es im Wasser.\"], return_tensors=\"pt\", padding=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[58100,    36,   360,    19,  7315,     3,     0, 58100, 58100, 58100],\n",
      "        [58100,    38,    85,  1595,    56,     5,     4,   616,     3,     0]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "outputs = translator.generate(**tokens.to(device), max_new_tokens=50)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.1__ (1 point):\n",
    "- What do the numbers in the `input_ids` represent?\n",
    "- What is the effect of `padding=True`? How would the data look like if padding was disabled?\n",
    "- What does `max_new_tokens` do? Why do you think it is important to set this parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "- The number in the `input_ids` represents that after the tokenization, the vocab_index for each subword in the sentence(not necessarily a whole word,because the tokenizer uses subword segmentation).\n",
    "- Transformers require all sequences in a batch to have the same length. Setting `padding=True` ensures this shape alignment by automatically adding <pad> tokens to shorter sentences so they match the length of the longest one in the batch. If padding was disabled, then the length for each sentence would be misaligned. Sentences of different lengths could not be put into a single tensor, and the tokenizer would raise an error such as: `ValueError`: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length. Perhaps your features (`input_ids` in this case) have excessive nesting (inputs type `list` where type `int` is expected).\n",
    "- `max_new_tokens` defines the maximum number of tokens the model is allowed to generate during decoding. It is important to set a limit to avoild the model to generate excessively long or infinite outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get actual words by running the output through the `batch_decode` function of the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The world is changing.', 'I can feel it in the water.']\n"
     ]
    }
   ],
   "source": [
    "translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(translations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ We assume that you will run the translations from German to English. If you would like to work on the opposite translation direction (and feel comfortable evaluating the German output), you are welcome to do so. The corresponding bilingual model is called `opus-mt-en-de`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting\n",
    "\n",
    "Before we move on, we need to split our data. We will evaluate different models and for that we'll need test data. We will also fine-tune a model, and for that we'll need training data. The entire Lord of the Rings dataset has 9640 lines.\n",
    "\n",
    "__Task 2.2__ (1 point): Split the dataset in such a way that the **last** 1000 lines are used for testing and the remaining lines (8640) for training. Save the data under the following filenames: `lotr.train.de, lotr.train.en, lotr.test.de, lotr.test.en`. You can use Python code or other tools to perform the splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9640 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#load lotr.detok.de\n",
    "with open('lotr.detok.de', 'r', encoding='utf-8-sig') as f:\n",
    "    text_de = f.readlines()\n",
    "print(len(text_de),type(text_de))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9640"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load lotr.entok.en\n",
    "with open('lotr.detok.en', 'r', encoding='utf-8-sig') as f:\n",
    "    text_en = f.readlines()  \n",
    "len(text_en)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct training set and testing set for de, and save to lotr.train.de,lotr.test.de\n",
    "train_de = text_de[:-1000]\n",
    "test_de = text_de[-1000:]\n",
    "with open('lotr.train.de', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(train_de))\n",
    "with open('lotr.test.de', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(test_de))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct training set and testing set for en,and save to lotr.train.en,lotr.test.en\n",
    "train_en = text_en[:-1000]\n",
    "test_en = text_en[-1000:]\n",
    "with open('lotr.train.en', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(train_en))\n",
    "with open('lotr.test.en', 'w', encoding='utf-8') as f:\n",
    "    f.write(''.join(test_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.3__ (1 point): What are potential risks and drawbacks of splitting the dataset in this way? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "Splitting the dataset by simply taking the last 1000 lines for testing introduces several potential risks:\n",
    "- Sequential bias / lack of randomness:\n",
    "  Since the data are not randomly selected, the test set may come from a specific part of the corpus that differs stylistically or semantically from the training set.\n",
    "- Limited test size\n",
    "  Using only 1000 examples (around 10% of the data) might provide too small a sample to reliably estimate generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to translate the test set with our model.\n",
    "\n",
    "__Task 2.4__ (2 points): Create a function that loads the entire `lotr.test.de` file, translates each line with the `opus-mt-de-en` model and writes its output to a new file, one sentence per line.\n",
    "\n",
    "The easiest way to do this is to just load the entire test file into a list, tokenize and translate it, but the test set may be too large to fit on GPU memory, or it might be inefficient and slow if you use a CPU. A better alternative is to split the data into batches of 50-100 sentences and send each batch separately to the translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 74, 59, 68, 33, 80, 71, 94, 80, 94, 17, 28, 35, 77, 45, 61, 83, 55, 58, 41, 94, 60, 6, 94, 66, 86, 40, 58, 90, 20, 7, 96, 6, 34, 39, 44, 77, 92, 24, 77, 19, 36, 77, 35, 96, 72, 14, 8, 29, 72]\n",
      "[58, 78, 85, 63, 25, 42, 9, 0, 35, 6, 77, 6, 0, 28, 85, 22, 24, 64, 42, 22, 33, 55, 53, 46, 31, 65, 42, 90, 85, 51, 80, 78, 54, 86, 18, 54, 24, 83, 75, 79, 24, 63, 35, 18, 70, 97, 79, 26, 50, 98]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "nums = np.random.randint(0, 100, size=100).tolist()\n",
    "batch_size=50\n",
    "for i in range(0,len(nums),batch_size):\n",
    "    batch = nums[i : i + batch_size]\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "test batch_size using 100 int in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hier ist nichts.\\n',\n",
       " 'Sucht weiter!\\n',\n",
       " 'Dieser Stein könnte überall sein.\\n',\n",
       " 'Der Arkenstein liegt in diesen Hallen.\\n',\n",
       " '- Findet ihn!\\n']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load lotr.test.de file\n",
    "with open('lotr.test.de','r',encoding='utf-8') as f:\n",
    "        test_de = f.readlines()\n",
    "test_de[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hier ist nichts.',\n",
       " 'Sucht weiter!',\n",
       " 'Dieser Stein könnte überall sein.',\n",
       " 'Der Arkenstein liegt in diesen Hallen.',\n",
       " '- Findet ihn!']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# strip lines\n",
    "test_de_data=[]\n",
    "for line in test_de[:5]:\n",
    "    line = line.strip()\n",
    "    test_de_data.append(line)\n",
    "test_de_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"There's nothing here.\", 'Keep looking!']\n",
      "['This stone could be anywhere.', 'The Arkenstein is located in these halls.']\n",
      "['- Find him!']\n"
     ]
    }
   ],
   "source": [
    "# test translate in batch_size=2\n",
    "for i in range(0,5,2):\n",
    "    batch = test_de_data[i:i+2]\n",
    "    tokens = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "    outputs = translator.generate(**tokens.to(device), max_new_tokens=50)\n",
    "    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    print(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5,2):\n",
    "    batch = test_de_data[i:i+2]\n",
    "    tokens = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "    outputs = translator.generate(**tokens.to(device), max_new_tokens=50)\n",
    "    translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    with open('test_de.en','a',encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(translations)+ '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explation:\n",
    "We need to use 'a' append instead of 'w' write. Also, we need to add '\\n' at the end of each batch. Use a small batch of 5 sentences and batch_size=2 to test everything is ok. Then we can put it all together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_file, translation_file, tokenizer, translator, batch_size=100):\n",
    "    \"\"\"Translate an input file line by line using the loaded tokenizer and translator,\n",
    "    and write the translations to output_file.\"\"\"\n",
    "    test_data = []\n",
    "    with open(input_file,'r',encoding='utf-8') as f:\n",
    "        test_data = [line.strip() for line in f.readlines()]\n",
    "    for i in range(0,len(test_data),batch_size):\n",
    "        batch = test_data[i: i + batch_size]\n",
    "        tokens = tokenizer(batch, return_tensors=\"pt\", padding=True)\n",
    "        outputs = translator.generate(**tokens.to(device), max_new_tokens=50)\n",
    "        translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        with open(translation_file,'a',encoding='utf-8') as f:\n",
    "            f.write('\\n'.join(translations)+'\\n')\n",
    "        \n",
    "translate(\"lotr.test.de\", \"lotr.output_opus.en\", tokenizer, translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, open the output file and check that the translations look ok. In particular, the file should contain the expected number of lines and output should be in the expected language (English or German, depending on the chosen direction).\n",
    "\n",
    "__Task 2.5__ (1 point): Open both the output file and the reference translations (`lotr.test.en` if translating from German to English) and compare the first 20 lines. How would you rate the translations of the OPUS system on a scale from 1 (incomprehensible and/or completely different meaning) to 5 (grammatically correct and meaning fully preserved)? Justify your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's nothing here.</td>\n",
       "      <td>Nothing here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keep looking!</td>\n",
       "      <td>Keep searching!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This stone could be anywhere.</td>\n",
       "      <td>That Jewel could be anywhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Arkenstein is located in these halls.</td>\n",
       "      <td>The Arkenstone is in these halls.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Find him!</td>\n",
       "      <td>- Find it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You heard me.</td>\n",
       "      <td>You heard him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>- Keep looking.</td>\n",
       "      <td>- Keep looking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All of you!</td>\n",
       "      <td>All of you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No one rests until he's found.</td>\n",
       "      <td>No one rests until... it is found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's almost tempting me to leave it to you.</td>\n",
       "      <td>I am almost tempted... to let you take it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And be it just to see how oak shield suffers.</td>\n",
       "      <td>If only... to see Oakenshield... suffer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Seeing it destroy him.</td>\n",
       "      <td>Watch it... destroy him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Seeing it contaminate his heart and drive him ...</td>\n",
       "      <td>Watch it corrupt... his heart... and drive him...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I'll help you.</td>\n",
       "      <td>I've got you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Just take what's necessary.</td>\n",
       "      <td>Take only what you need.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We have a long march ahead of us.</td>\n",
       "      <td>We have a long march ahead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Where are you going?</td>\n",
       "      <td>Where will you go?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>There's only one place.</td>\n",
       "      <td>There is only one place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The mountain.</td>\n",
       "      <td>The Mountain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>You are magnificent, sir.</td>\n",
       "      <td>You are a genius, sire.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               target  \\\n",
       "0                               There's nothing here.   \n",
       "1                                       Keep looking!   \n",
       "2                       This stone could be anywhere.   \n",
       "3           The Arkenstein is located in these halls.   \n",
       "4                                         - Find him!   \n",
       "5                                       You heard me.   \n",
       "6                                     - Keep looking.   \n",
       "7                                         All of you!   \n",
       "8                      No one rests until he's found.   \n",
       "9         It's almost tempting me to leave it to you.   \n",
       "10      And be it just to see how oak shield suffers.   \n",
       "11                             Seeing it destroy him.   \n",
       "12  Seeing it contaminate his heart and drive him ...   \n",
       "13                                     I'll help you.   \n",
       "14                        Just take what's necessary.   \n",
       "15                  We have a long march ahead of us.   \n",
       "16                               Where are you going?   \n",
       "17                            There's only one place.   \n",
       "18                                      The mountain.   \n",
       "19                          You are magnificent, sir.   \n",
       "\n",
       "                                            reference  \n",
       "0                                       Nothing here.  \n",
       "1                                     Keep searching!  \n",
       "2                       That Jewel could be anywhere.  \n",
       "3                   The Arkenstone is in these halls.  \n",
       "4                                          - Find it!  \n",
       "5                                      You heard him.  \n",
       "6                                     - Keep looking.  \n",
       "7                                         All of you!  \n",
       "8                  No one rests until... it is found.  \n",
       "9          I am almost tempted... to let you take it.  \n",
       "10           If only... to see Oakenshield... suffer.  \n",
       "11                           Watch it... destroy him.  \n",
       "12  Watch it corrupt... his heart... and drive him...  \n",
       "13                                      I've got you.  \n",
       "14                           Take only what you need.  \n",
       "15                        We have a long march ahead.  \n",
       "16                                 Where will you go?  \n",
       "17                           There is only one place.  \n",
       "18                                      The Mountain.  \n",
       "19                            You are a genius, sire.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open ('lotr.output_opus.en','r', encoding='utf-8') as f:\n",
    "    output = [line.strip() for line in f.readlines()][:20]\n",
    "\n",
    "with open('lotr.test.en','r',encoding='utf-8') as f:\n",
    "    test_en = [line.strip() for line in f.readlines()][:20]\n",
    "df = pd.DataFrame({\n",
    "    'target':output,\n",
    "    'reference': test_en\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "Here we conduct a reference-based evaluation. I will evaluate the output in two dimensions: \n",
    "- Adequacy: Does the output convey the same meaning as the input?\n",
    "  I would rate 3 out of 5. Because some sentences don't convey the same meaning as the input. For example, translate \"him\" to \"me\". or \"it\" to \"he\". \n",
    "- Fluency: Is the output grammatically correct and idiomatic?\n",
    "  I would rate the target lanuage translation 5 out of 5, since the target-language sentences are grammatically correct and sound natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We can now evaluate the quality of our translations. In a first step, we perform _reference-based surface-level evaluation_  using the popular BLEU score. We can do that with the `sacrebleu` module. Below is a slightly reformatted example taken from the [SacreBLEU documentation](https://github.com/mjpost/sacrebleu/tree/master?tab=readme-ov-file#using-sacrebleu-from-python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU = 45.07 70.6/42.9/36.4/37.5 (BP = 1.000 ratio = 1.000 hyp_len = 17 ref_len = 17)\n"
     ]
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "reference = ['The dog bit the man.', 'It was not unexpected.', 'The man bit him first.']\n",
    "hypothesis = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
    "\n",
    "bleu_scorer = BLEU()\n",
    "# BLEU can deal with multiple references per sentence, but here we only have one, so we just enclose it in another set of brackets:\n",
    "score = bleu_scorer.corpus_score(hypothesis, [reference])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.6__ (1 point): Load both the system output and the reference of your test set and compute the corpus-level BLEU score. Also compute the corpus-level chrF score. Which of the scores is higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus BLEU: BLEU = 29.03 63.3/38.3/25.2/16.2 (BP = 0.920 ratio = 0.923 hyp_len = 6203 ref_len = 6721)\n",
      "Corpus chrF: chrF2 = 51.05\n"
     ]
    }
   ],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "\n",
    "def evaluate_bleu(hypothesis_file, reference_file):\n",
    "    \n",
    "    with open (hypothesis_file,'r', encoding='utf-8') as f:\n",
    "        output = [line.strip() for line in f.readlines()]\n",
    "    with open(reference_file,'r',encoding='utf-8') as f:\n",
    "        references = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # initialize bleu and chrF\n",
    "    bleu = BLEU()\n",
    "    chrf = CHRF()\n",
    "\n",
    "    #calculate bleu\n",
    "    bleu_score = bleu.corpus_score(output, [references])\n",
    "    print(f\"Corpus BLEU: {bleu_score}\")\n",
    "\n",
    "    #calculate chrF\n",
    "    chrf_score = chrf.corpus_score(output, [references])\n",
    "    print(f\"Corpus chrF: {chrf_score}\")\n",
    "    \n",
    "evaluate_bleu(\"lotr.output_opus.en\", \"lotr.test.en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "- BLEU(BiLingual Evaluation Understudy), is calucated by computing n-gram overlap (1-gram/2-gram/3-gram/4-gram precision: 63.3/38.3/25.2/16.2) between system output and reference and take the geometric mean of overlap precisions. The result show that the overall BLEU score is 29.03. BP represents brevity penalty, BP= 0.920, which means the output has almost the same length as the reference, only a little bit shorter.\n",
    "- chrF(character-level score) breaks down words into character n-grams, which give partial credits for matching stems without requiring a stemmer / lemmatizer.\n",
    "- Although both BLEU and chrF measure translation quality, their scales are not directly comparable. BLEU is a precision-based metric operating on word-level n-gram matches, while chrF is an F1-based metric operating on character n-gram matches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides string-based metrics, neural metrics have become increasingly popular lately, since they have been shown to correlate better with human judgements. The most popular neural metric is called COMET and it can be used with the HuggingFace `evaluate` package. The example below is from the [documentation](https://huggingface.co/spaces/evaluate-metric/comet/blob/main/README.md):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acc1d62669224d7c85b1904e21f0eeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f9c84e3e894475805c6a12bc29b902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "/fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /cluster/software/EL9/easybuild/software/jupyter-ser ...\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_score': 0.905142068862915, 'scores': [0.8385583758354187, 0.9717257618904114]}\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "comet_metric = evaluate.load('comet')\n",
    "src = [\"Dem Feuer konnte Einhalt geboten werden\", \"Schulen und Kindergärten wurden eröffnet.\"]\n",
    "hyp = [\"The fire could be stopped\", \"Schools and kindergartens were open\"]\n",
    "ref = [\"They were able to control the fire.\", \"Schools and kindergartens opened\"]\n",
    "comet_score = comet_metric.compute(predictions=hyp, references=ref, sources=src)\n",
    "print(comet_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.7__ (1 point): Adapt this code to evaluate the output of the OPUS model. Note that COMET also requires the source text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce91eca398f472eb7b95380b0505c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "/fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /cluster/software/EL9/easybuild/software/jupyter-ser ...\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8517506766319275"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_comet(hypothesis_file, reference_file, source_file):\n",
    "    \n",
    "    comet_metric = evaluate.load('comet')\n",
    "\n",
    "    #load and create src list\n",
    "    with open (source_file,'r', encoding='utf-8') as f:\n",
    "        src = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "    #load and create hyp list        \n",
    "    with open (hypothesis_file,'r', encoding='utf-8') as f:\n",
    "        output = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    #load and create reference list \n",
    "    with open(reference_file,'r',encoding='utf-8') as f:\n",
    "        references = [line.strip() for line in f.readlines()]   \n",
    "\n",
    "    comet_score = comet_metric.compute(predictions=output, references=references, sources=src)\n",
    "\n",
    "    return comet_score['mean_score']\n",
    "\n",
    "evaluate_comet('lotr.output_opus.en', 'lotr.test.en', 'lotr.test.de')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "- Unlike BLEU and chrF, which evaluate the results at the corpus level, COMET evaluates translations at the sentence level and then reports the mean_score as the average over all sentences.\n",
    "- I chose to present only the mean_score here to improve readability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "Let us see now if we can further improve the translation quality. We still haven't used the training set after all...\n",
    "\n",
    "Fine-tuning a translation model with the `transformers` library is a bit convoluted. You need the following ingredients:\n",
    "- A `Seq2SeqTrainer` object, which defines the initial model and its tokenizer, the training data, and the configuration parameters (as a `Seq2SeqTrainingArguments` object). The training process starts with the `train()` method.\n",
    "- A `Seq2SeqTrainingArguments` object, which contains the configuration parameters, such as the number of training epochs, the path for saving the fine-tuned model, the learning rate etc.\n",
    "- A `DataCollatorForSeq2Seq` object that takes care of splitting the training data into batches of appropriate size.\n",
    "- A `DatasetDict` object containing the tokenized training data. Typically, the untokenized data is loaded into a `DatasetDict` object, and the tokenization function is applied to everything inside this `DatasetDict` using the `map()` function.\n",
    "\n",
    "__Task 2.8__ (1 point): The code in the box below shows a working example using the pretrained OPUS model, but is limited to two sentence pairs. Complete the code to load the entire training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5e52980388435cb274749498adfc1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['src_text', 'tgt_text', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 8640\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fp/projects01/ec30/software/easybuild/software/nlpl-transformers/4.47.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/localscratch/2091964/ipykernel_3446632/387673564.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='810' max='810' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [810/810 00:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.183100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/fp/projects01/ec30/software/easybuild/software/nlpl-transformers/4.47.1-foss-2022b-Python-3.10.8/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[58100]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=810, training_loss=1.1150821261935764, metrics={'train_runtime': 40.5623, 'train_samples_per_second': 639.017, 'train_steps_per_second': 19.969, 'total_flos': 160830792400896.0, 'train_loss': 1.1150821261935764, 'epoch': 3.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "# ds = Dataset.from_dict({\n",
    "#     \"src_text\": [\"Die Welt ist im Wandel.\", \"Ich spüre es im Wasser.\"],\n",
    "#     \"tgt_text\": [\"The world is changed.\", \"I feel it in the water.\"]\n",
    "# })\n",
    "# data = DatasetDict({\"train\": ds})\n",
    "\n",
    "#load and create src list\n",
    "with open ('lotr.train.de','r', encoding='utf-8') as f:\n",
    "    src = [line.strip() for line in f.readlines()]\n",
    "\n",
    "#target and create target_text list\n",
    "with open ('lotr.train.en','r', encoding='utf-8') as f:\n",
    "    target_text = [line.strip() for line in f.readlines()]\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"src_text\": src,\n",
    "    \"tgt_text\": target_text\n",
    "})\n",
    "data = DatasetDict({\"train\": ds})\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"src_text\"], text_target=examples[\"tgt_text\"], max_length=max_length, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = data.map(preprocess_function, batched=True)\n",
    "print(tokenized_datasets)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=translator)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"opus-mt-de-en-lotr\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    translator,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "- The fine-tuning process completed 810 training steps over 3 epochs, with a final training loss of 1.12().\n",
    "- The model trained efficiently, processing approximately 639 samples per second, and the total runtime was around 40 seconds.\n",
    "- A training loss around 1.1 is considered a good result for neural machine translation models (values below 2.0 generally indicate that the model has learned meaningful patterns rather than producing random translations).\n",
    "- This suggests that the model successfully adapted to the training data and improved its translation quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was fine-tuned for three epochs, and you should have three checkpoints in the `opus-mt-de-en-lotr` directory.\n",
    "\n",
    "__Task 2.9__ (1 point): Choose one of the checkpoints and use it to translate the test set. Evaluate the test set with BLEU, chrF and COMET. Note that locally saved model files (and tokenizers) can be loaded in the same way as models from the HuggingFace hub, e.g. with the following command: `transformers.AutoModelForSeq2SeqLM.from_pretrained(\"opus-mt-de-en-lotr/checkpoint-810\")`\n",
    "\n",
    "Did fine-tuning help? Did fine-tuning help? Have a look at the first rows of the files. Do you agree with the metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "model_path = \"./opus-mt-de-en-lotr/checkpoint-810\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path)\n",
    "translator = transformers.AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "# Change \"cuda\" to \"cpu\" if you're running on a machine without GPU\n",
    "device = \"cuda\"\n",
    "translator = translator.to(device)\n",
    "translate(\"lotr.test.de\", \"lotr.output_finetuned.en\", tokenizer, translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5adbdcb5b294e3290be5fb7cb54258c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`\n",
      "Encoder model frozen.\n",
      "/fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n",
      "/fp/homes01/u01/ec-shuwa/.local/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /cluster/software/EL9/easybuild/software/jupyter-ser ...\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8645248173177242"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate with new output \"lotr.output_finetuned.en\"\n",
    "evaluate_comet('lotr.output_finetuned.en', 'lotr.test.en', 'lotr.test.de')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "Using the COMET metric, the pretrained OPUS model achieved a mean score of 0.8518, while the fine-tuned model (checkpoint-810) reached 0.8645.\n",
    "This represents a small but consistent improvement (+0.013), suggesting that fine-tuning helped the model adapt better to the domain.\n",
    "Since COMET captures both adequacy and fluency using contextual embeddings, the higher score indicates improved semantic fidelity rather than superficial token overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opus</th>\n",
       "      <th>finetuned</th>\n",
       "      <th>reference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There's nothing here.</td>\n",
       "      <td>There's nothing here.</td>\n",
       "      <td>Nothing here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Keep looking!</td>\n",
       "      <td>Keep looking!</td>\n",
       "      <td>Keep searching!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This stone could be anywhere.</td>\n",
       "      <td>This stone could be anywhere.</td>\n",
       "      <td>That Jewel could be anywhere.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Arkenstein is located in these halls.</td>\n",
       "      <td>The Arkenstone lies in these halls.</td>\n",
       "      <td>The Arkenstone is in these halls.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Find him!</td>\n",
       "      <td>- Find him!</td>\n",
       "      <td>- Find it!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You heard me.</td>\n",
       "      <td>You heard me.</td>\n",
       "      <td>You heard him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>- Keep looking.</td>\n",
       "      <td>- Keep looking.</td>\n",
       "      <td>- Keep looking.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>All of you!</td>\n",
       "      <td>All of you!</td>\n",
       "      <td>All of you!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>No one rests until he's found.</td>\n",
       "      <td>No one rests until it is found.</td>\n",
       "      <td>No one rests until... it is found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It's almost tempting me to leave it to you.</td>\n",
       "      <td>It's almost tempting me to let you have it.</td>\n",
       "      <td>I am almost tempted... to let you take it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And be it just to see how oak shield suffers.</td>\n",
       "      <td>Whether it be to see Oakenshield suffer.</td>\n",
       "      <td>If only... to see Oakenshield... suffer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Seeing it destroy him.</td>\n",
       "      <td>To see it destroy it.</td>\n",
       "      <td>Watch it... destroy him.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Seeing it contaminate his heart and drive him ...</td>\n",
       "      <td>To see it contaminate his heart and drive him ...</td>\n",
       "      <td>Watch it corrupt... his heart... and drive him...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I'll help you.</td>\n",
       "      <td>I'll help you.</td>\n",
       "      <td>I've got you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Just take what's necessary.</td>\n",
       "      <td>Take only what is necessary.</td>\n",
       "      <td>Take only what you need.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We have a long march ahead of us.</td>\n",
       "      <td>We have a long march ahead of us.</td>\n",
       "      <td>We have a long march ahead.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Where are you going?</td>\n",
       "      <td>Where are you going?</td>\n",
       "      <td>Where will you go?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>There's only one place.</td>\n",
       "      <td>There is only one place.</td>\n",
       "      <td>There is only one place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The mountain.</td>\n",
       "      <td>The mountain.</td>\n",
       "      <td>The Mountain.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>You are magnificent, sir.</td>\n",
       "      <td>You're great, sire.</td>\n",
       "      <td>You are a genius, sire.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 opus  \\\n",
       "0                               There's nothing here.   \n",
       "1                                       Keep looking!   \n",
       "2                       This stone could be anywhere.   \n",
       "3           The Arkenstein is located in these halls.   \n",
       "4                                         - Find him!   \n",
       "5                                       You heard me.   \n",
       "6                                     - Keep looking.   \n",
       "7                                         All of you!   \n",
       "8                      No one rests until he's found.   \n",
       "9         It's almost tempting me to leave it to you.   \n",
       "10      And be it just to see how oak shield suffers.   \n",
       "11                             Seeing it destroy him.   \n",
       "12  Seeing it contaminate his heart and drive him ...   \n",
       "13                                     I'll help you.   \n",
       "14                        Just take what's necessary.   \n",
       "15                  We have a long march ahead of us.   \n",
       "16                               Where are you going?   \n",
       "17                            There's only one place.   \n",
       "18                                      The mountain.   \n",
       "19                          You are magnificent, sir.   \n",
       "\n",
       "                                            finetuned  \\\n",
       "0                               There's nothing here.   \n",
       "1                                       Keep looking!   \n",
       "2                       This stone could be anywhere.   \n",
       "3                 The Arkenstone lies in these halls.   \n",
       "4                                         - Find him!   \n",
       "5                                       You heard me.   \n",
       "6                                     - Keep looking.   \n",
       "7                                         All of you!   \n",
       "8                     No one rests until it is found.   \n",
       "9         It's almost tempting me to let you have it.   \n",
       "10           Whether it be to see Oakenshield suffer.   \n",
       "11                              To see it destroy it.   \n",
       "12  To see it contaminate his heart and drive him ...   \n",
       "13                                     I'll help you.   \n",
       "14                       Take only what is necessary.   \n",
       "15                  We have a long march ahead of us.   \n",
       "16                               Where are you going?   \n",
       "17                           There is only one place.   \n",
       "18                                      The mountain.   \n",
       "19                                You're great, sire.   \n",
       "\n",
       "                                            reference  \n",
       "0                                       Nothing here.  \n",
       "1                                     Keep searching!  \n",
       "2                       That Jewel could be anywhere.  \n",
       "3                   The Arkenstone is in these halls.  \n",
       "4                                          - Find it!  \n",
       "5                                      You heard him.  \n",
       "6                                     - Keep looking.  \n",
       "7                                         All of you!  \n",
       "8                  No one rests until... it is found.  \n",
       "9          I am almost tempted... to let you take it.  \n",
       "10           If only... to see Oakenshield... suffer.  \n",
       "11                           Watch it... destroy him.  \n",
       "12  Watch it corrupt... his heart... and drive him...  \n",
       "13                                      I've got you.  \n",
       "14                           Take only what you need.  \n",
       "15                        We have a long march ahead.  \n",
       "16                                 Where will you go?  \n",
       "17                           There is only one place.  \n",
       "18                                      The Mountain.  \n",
       "19                            You are a genius, sire.  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open ('lotr.output_opus.en','r', encoding='utf-8') as f:\n",
    "    output = [line.strip() for line in f.readlines()][:20]\n",
    "\n",
    "with open ('lotr.output_finetuned.en','r', encoding='utf-8') as f:\n",
    "    finetuned = [line.strip() for line in f.readlines()][:20]\n",
    "\n",
    "with open('lotr.test.en','r',encoding='utf-8') as f:\n",
    "    test_en = [line.strip() for line in f.readlines()][:20]\n",
    "    \n",
    "df1 = pd.DataFrame({\n",
    "    'opus':output,\n",
    "    'finetuned': finetuned ,\n",
    "    'reference':test_en\n",
    "})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shu_explanation:\n",
    "- The COMET result shows that after fine tuning, there is only a slight improvement in output.\n",
    "- We observed the first 20 sentences and found that:\n",
    "  Line8, the finetuned output capture it correctly while opus mis-intepret to him.\n",
    "  Line14 improved the output by capture \"only\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Oblig4-nlpl)",
   "language": "python",
   "name": "oblig4_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
